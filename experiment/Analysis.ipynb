{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figsizeO = [8,4.7]\n",
    "figsizeS = [8,4]\n",
    "plt.rcParams['figure.figsize'] = figsizeO\n",
    "import os\n",
    "resultDir = '.' + os.path.sep + 'results' + os.path.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotOutputPath = '.' + os.path.sep + 'plots' + os.path.sep\n",
    "show = False\n",
    "dpi=300\n",
    "plt.rcParams.update({'font.size': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparableNodes = 56 / 4\n",
    "linethicknes = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractName(name):\n",
    "    name = name.split(' ')[0].split(':')\n",
    "    return name[1] if len(name) > 1 else name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDuration(time):\n",
    "    time = time.split(' ')\n",
    "    seconds = 0.0\n",
    "    for t in time:\n",
    "        unit = ''.join([s for s in t if s.isalpha()])\n",
    "        amount = float(t[:-len(unit)])\n",
    "        if unit == 'ms':\n",
    "            seconds += amount / 1000\n",
    "        elif unit == 's':\n",
    "            seconds += amount\n",
    "        elif unit == 'm':\n",
    "            seconds += amount * 60\n",
    "        elif unit == 'h':\n",
    "            seconds += amount * 3600\n",
    "        elif unit == 'd':\n",
    "            seconds += amount * 86400\n",
    "        else:\n",
    "            raise Exception('Unknown unit', unit, time)\n",
    "    return seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractCPU(cpu):\n",
    "    return float(cpu[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractStorageInMB(storage):\n",
    "    storage = storage.split(' ')\n",
    "    if(len(storage) != 2):\n",
    "        raise Exception('Unknown unit', storage)\n",
    "    amount = float(storage[0]) \n",
    "    unit = storage[1]\n",
    "    if unit == 'MB':\n",
    "        return amount\n",
    "    elif unit == 'GB':\n",
    "        return amount * 1024\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nextflow report shows:\n",
    "- realtime\n",
    "- peak_rss\n",
    "- %CPU\n",
    "- rchar\n",
    "- wchar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = ['mean','min','max','median','std','sum','count']\n",
    "byteToMb = 1024 * 1024\n",
    "msPerMinute = 60 * 1000\n",
    "msPerHour = msPerMinute * 60\n",
    "\n",
    "valuesToExtract=[\n",
    "    ('duration',msPerMinute,'min'),('realtime', msPerMinute,'min'),\n",
    "    ('%cpu',1,'%'),('%mem', 1,'%'),\n",
    "    ('rss',byteToMb,'mb'),('vmem', byteToMb,'mb'),\n",
    "    ('peak_rss',byteToMb,'mb'),('peak_vmem', byteToMb,'mb'),\n",
    "    ('read_bytes',byteToMb,'mb'),('write_bytes', byteToMb,'mb'),\n",
    "    ('rchar',byteToMb,'mb'),('wchar', byteToMb,'mb')\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrace(path):\n",
    "    print(path)\n",
    "    return pd.read_csv(path,sep=';')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceToMetric(trace, metric, divisor = 1):\n",
    "    shortedTrace = trace[['process',metric]]\n",
    "    \n",
    "    l = len(shortedTrace)\n",
    "    shortedTrace = shortedTrace[shortedTrace[metric] != '-']\n",
    "    if l != len(shortedTrace):\n",
    "        print(metric,\"shortened!!!\")\n",
    "        shortedTrace[metric] = shortedTrace[metric].astype('float')\n",
    "    \n",
    "    global processes\n",
    "    processes = shortedTrace['process'].unique()\n",
    "    shortedTrace[metric] = shortedTrace[metric] / divisor\n",
    "    result = shortedTrace.groupby('process').agg( aggregations )\n",
    "    result.columns = result.columns.get_level_values(1)\n",
    "    return result\n",
    "\n",
    "def getColumn(trace, column):\n",
    "    t = trace[column]\n",
    "    t = t[t != '-']\n",
    "    return t.astype('float')\n",
    "\n",
    "def extractMetrics(trace):\n",
    "    results = {}\n",
    "    \n",
    "    #stages\n",
    "    preprocesses = trace[trace['process'].str.contains(':preprocess')]\n",
    "    merges = trace[trace['process'].str.contains(':merge')]\n",
    "    higherLevel = trace[trace['process'].str.contains('higherLevel:')]\n",
    "    checkResults = trace[trace['process'].str.contains('checkResults')]\n",
    "    \n",
    "    for v in valuesToExtract:\n",
    "        results[v[0]] = reduceToMetric(trace, v[0], v[1])\n",
    "        \n",
    "    results['totalRuntime'] = (getColumn(checkResults,'submit').min() - getColumn(trace,'submit').min()) / msPerMinute\n",
    "    results['sumRuntime'] = (getColumn(trace,'realtime').sum() - getColumn(checkResults,'realtime').sum()) / msPerHour        \n",
    "    results['cpuRuntime'] = ((getColumn(trace,'realtime').multiply(getColumn(trace,'%cpu') / 100)).sum() - (getColumn(checkResults,'realtime').multiply(getColumn(checkResults,'%cpu') / 100)).sum()) / msPerHour   \n",
    "    results['requestedCPURuntime'] = (getColumn(trace,'realtime').multiply(getColumn(trace,'cpus')).sum() - (getColumn(checkResults,'realtime').multiply(getColumn(checkResults,'cpus'))).sum()) / msPerHour \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #preprocess\n",
    "    \n",
    "    results['stagePreprocess-Duration'] = (getColumn(merges,'submit').min() - getColumn(preprocesses,'submit').min()) / msPerMinute\n",
    "    results['stagePreprocess-RealtimeSum'] = getColumn(preprocesses,'realtime').sum() / msPerHour    \n",
    "    results['stagePreprocess-CpuRuntime'] = (getColumn(preprocesses,'realtime').multiply(getColumn(preprocesses,'%cpu') / 100)).sum() / msPerHour \n",
    "    \n",
    "    #merge\n",
    "    \n",
    "    results['stageMerge-Duration'] = (getColumn(higherLevel,'submit').min() - getColumn(merges,'submit').min()) / msPerMinute\n",
    "    results['stageMerge-RealtimeSum'] = getColumn(merges,'realtime').sum() / msPerHour\n",
    "    results['stageMerge-CpuRuntime'] = (getColumn(merges,'realtime').multiply(getColumn(merges,'%cpu') / 100)).sum() / msPerHour \n",
    "    \n",
    "    results['stagePreprocessMerge-Duration'] = results['stagePreprocess-Duration'] + results['stageMerge-Duration']\n",
    "    \n",
    "    #higher level\n",
    "    \n",
    "    results['stageHigherLevel-Duration'] = (getColumn(checkResults,'submit').min() - getColumn(higherLevel,'submit').min()) / msPerMinute\n",
    "    results['stageHigherLevel-RealtimeSum'] = getColumn(higherLevel,'realtime').sum() / msPerHour\n",
    "    results['stageHigherLevel-CpuRuntime'] = (getColumn(higherLevel,'realtime').multiply(getColumn(higherLevel,'%cpu') / 100)).sum() / msPerHour\n",
    "    \n",
    "    results['stageHigherLevel-rchar'] = getColumn(higherLevel,'rchar').sum() / byteToMb\n",
    "    results['stageHigherLevel-wchar'] = getColumn(higherLevel,'wchar').sum() / byteToMb\n",
    "        \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    results = {}\n",
    "    nodes = [x for x in os.listdir(resultDir)]\n",
    "    for node in nodes:\n",
    "        if node == 'original':\n",
    "            continue\n",
    "        n = 'nf' if node == 'nf' else int(node)\n",
    "        results[n] = {}\n",
    "        runs = [x for x in os.listdir(resultDir + node)]\n",
    "        for run in runs:\n",
    "            trace = loadTrace(resultDir + node + os.path.sep + run + os.path.sep + 'trace.txt' )\n",
    "            #rename stage, if name is wrong in logs\n",
    "            trace['process'] = trace['process'].str.replace('level2processing:','higherLevel:')\n",
    "            results[n][int(run)] = extractMetrics(trace)\n",
    "    return results\n",
    "\n",
    "data = loadData()\n",
    "data['original'] = {\n",
    "    1 : {\n",
    "    'stagePreprocessMerge-Duration' : (326 * 60000 + 47 * 1000 + 913) / msPerMinute,\n",
    "    'stageHigherLevel-Duration' : (29 * 60000 + 40 * 1000 + 160\n",
    "    #mosaicking\n",
    "    + 10 * 1000 + 903\n",
    "    #pyramids\n",
    "    + 46 * 1000 + 532) / msPerMinute,\n",
    "    'totalRuntime' : (357 * 60000 + 33 * 1000 + 941) / msPerMinute\n",
    "    },\n",
    "    2 : {\n",
    "    'stagePreprocessMerge-Duration' : (332 * 60000 + 27 * 1000 + 727) / msPerMinute,\n",
    "    'stageHigherLevel-Duration' : (25 * 60000 + 17 * 1000 + 349\n",
    "    #mosaicking\n",
    "    + 10 * 1000 + 883\n",
    "    #pyramids\n",
    "    + 49 * 1000 + 208) / msPerMinute,\n",
    "    'totalRuntime' : (358 * 60000 + 53 * 1000 + 651) / msPerMinute\n",
    "    },\n",
    "    3 : {\n",
    "    'stagePreprocessMerge-Duration' : (325 * 60000 + 0 * 1000 + 367) / msPerMinute,\n",
    "    'stageHigherLevel-Duration' : (29 * 60000 + 8 * 1000 + 621\n",
    "    #mosaicking\n",
    "    + 10 * 1000 + 863\n",
    "    #pyramids\n",
    "    + 46 * 1000 + 970) / msPerMinute,\n",
    "    'totalRuntime' : (355 * 60000 + 15 * 1000 + 808) / msPerMinute\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeName(s):\n",
    "    stage = None\n",
    "    if 'preprocessmerge' in s.lower():\n",
    "        stage = 'Preprocessing + Merging'\n",
    "    elif 'preprocess' in s.lower():\n",
    "        stage = 'Preprocessing'\n",
    "    elif 'merge' in s.lower():\n",
    "        stage = 'Merging'\n",
    "    elif 'higherlevel' in s.lower():\n",
    "        stage = 'Higher Level'\n",
    "    elif 'totalruntime' in s.lower():\n",
    "        stage = 'Total Runtime'\n",
    "    elif 'sumruntime' in s.lower():\n",
    "        stage = 'Cumulated Runtime'\n",
    "    elif 'requestedcpuruntime' in s.lower():\n",
    "        stage = 'Requested CPU Runtime'\n",
    "    elif 'cpuruntime' in s.lower():\n",
    "        stage = 'CPU Runtime'\n",
    "    elif 'min' in s.lower():\n",
    "        stage = 'Minimum'\n",
    "    elif 'mean' in s.lower():\n",
    "        stage = 'Average'\n",
    "    elif 'median' in s.lower():\n",
    "        stage = 'Median'\n",
    "    elif 'max' in s.lower():\n",
    "        stage = 'Maximum'\n",
    "        \n",
    "    if stage is None:\n",
    "        return s\n",
    "        \n",
    "    workflow = None\n",
    "    if s.endswith('NF'):\n",
    "        workflow = 'HPS'\n",
    "    elif s.endswith('Original'):\n",
    "        workflow = 'HPS Original'\n",
    "    \n",
    "    if workflow is not None:\n",
    "        return stage + ' ' + workflow\n",
    "    return stage\n",
    "\n",
    "def sortHelper(s):\n",
    "    if 'preprocessmerge' in s.lower():\n",
    "        return '3-' + s\n",
    "    elif 'preprocess' in s.lower():\n",
    "        return '1-' + s\n",
    "    elif 'merge' in s.lower():\n",
    "        return '2-' + s\n",
    "    elif 'higherlevel' in s.lower():\n",
    "        return '4-' + s\n",
    "    elif 'min' in s.lower():\n",
    "        return '1-' + s\n",
    "    elif 'median' in s.lower():\n",
    "        return '2-' + s\n",
    "    elif 'mean' in s.lower():\n",
    "        return '3-' + s\n",
    "    elif 'max' in s.lower():\n",
    "        return '4-' + s\n",
    "    return '5-' + s\n",
    "    \n",
    "def labelLegend(labels,handles):\n",
    "    labels,handles = zip(*sorted(zip(labels, handles), key=lambda t: sortHelper(t[0])))\n",
    "    labels = list(labels)\n",
    "    handles = list(handles)\n",
    "    labels = list(map(changeName,labels))\n",
    "    \n",
    "    bringToEnd = ['Optimal Scaling']\n",
    "    for e in bringToEnd:\n",
    "        if e in labels:\n",
    "            index = labels.index(e)\n",
    "            l = labels.pop(index)\n",
    "            labels.append(l)\n",
    "            h = handles.pop(index)\n",
    "            handles.append(h)\n",
    "    \n",
    "    return labels,handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker = {\n",
    "    'mean' : ('black','--','1'),'min' : ('b','-.','2'),'max' : ('g', ':','3'),'median': ('r','solid','4'), 'sum' : ('black','solid','x')\n",
    "}\n",
    "\n",
    "def rearangeDict(dictionary, fields):\n",
    "    results = {}\n",
    "    for run in dictionary:\n",
    "        for agg in dictionary[run]:\n",
    "            if agg in fields:\n",
    "                for pro in dictionary[run][agg]:\n",
    "                    aggC = agg\n",
    "                    d = dictionary[run][aggC][pro]\n",
    "                    if int(dictionary[run]['count'][pro]) == 1:\n",
    "                        aggC = 'mean'\n",
    "                        if agg == 'sum':\n",
    "                            d = None\n",
    "                    a = results.get(pro,{})\n",
    "                    results[pro] = a\n",
    "                    b = a.get(aggC,{})\n",
    "                    a[aggC] = b \n",
    "                    b[run] = d\n",
    "    return results\n",
    "\n",
    "def plotOneProcess(dictionary, metric, process, unit, outPath = plotOutputPath, figsize = figsizeO, nCol = 1):\n",
    "    plt.rcParams[\"figure.figsize\"] = figsize\n",
    "    for agg in dictionary:\n",
    "        \n",
    "        nfValue = None\n",
    "        if 'nf' in dictionary[agg]:\n",
    "            nfValue = dictionary[agg]['nf']\n",
    "            del dictionary[agg]['nf']\n",
    "        \n",
    "        lists = sorted(dictionary[agg].items()) # sorted by key, return a list of tuples\n",
    "        x, y = zip(*lists)\n",
    "        \n",
    "        if all(v is None for v in y):\n",
    "            return\n",
    "        \n",
    "        plt.xticks(np.unique(x),np.array(x))\n",
    "        \n",
    "        plt.plot(list(map(int,x)), list(map(float,y)),label=agg, linestyle = marker[agg][1], marker = marker[agg][2], linewidth=linethicknes, c = marker[agg][0])\n",
    "        \n",
    "        xLabels = np.array(x)\n",
    "        \n",
    "        if nfValue is not None:\n",
    "            plt.scatter(comparableNodes, nfValue, label = agg + 'NF', marker=marker[agg][2], linewidth=linethicknes, c = marker[agg][0])\n",
    "            x = list(x)\n",
    "            x.append(14)\n",
    "            x.sort()\n",
    "            xLabels = x.copy()\n",
    "            xLabels[x.index(14)] = 'HPS'\n",
    "        \n",
    "    \n",
    "    name = \"avg. cpu usage\" if metric == \"%cpu\" else metric\n",
    "    plt.title(name + ' of ' + process)\n",
    "    plt.xlabel('# of nodes')\n",
    "    plt.ylabel(name + ' in ' + unit)\n",
    "    \n",
    "    plt.xticks(np.array(x),xLabels)\n",
    "    \n",
    "    if len(dictionary) > 1:\n",
    "        plt.legend()\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        # sort both labels and handles by labels\n",
    "        labels, handles = labelLegend(labels,handles)\n",
    "        plt.gca().legend(handles, labels, ncol = nCol)\n",
    "        \n",
    "    plt.grid(color='grey', linestyle='-', linewidth=.1)\n",
    "    \n",
    "    plt.savefig(outPath + process.replace(':','-') + '-' + metric.replace('%','percent_') + '.png', bbox_inches='tight', dpi = dpi)\n",
    "    plt.title(None)\n",
    "    plt.savefig(outPath + process.replace(':','-') + '-' + metric.replace('%','percent_') + '.pdf', bbox_inches='tight', dpi = dpi)\n",
    "    plt.rcParams[\"figure.figsize\"] = figsizeO\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "def extractData(data, metric):\n",
    "    allData = {}\n",
    "    for d in data:\n",
    "        results = []\n",
    "        for run in data[d]:\n",
    "            if metric not in data[d][run]:\n",
    "                break\n",
    "            results.append( data[d][run][metric] )\n",
    "        if len(results) > 0:\n",
    "            results = pd.concat(results).groupby('process').agg(['median'])   \n",
    "            results.columns = results.columns.get_level_values(0)\n",
    "            allData[d] = results .to_dict()\n",
    "    return allData\n",
    "\n",
    "def plot(data,metric,unit):\n",
    "    allData = extractData(data,metric)\n",
    "    oneExecution = rearangeDict(allData,['mean','min','max','median']) \n",
    "    sumExecution = rearangeDict(allData,['sum'])\n",
    "    for proc in oneExecution:\n",
    "        plotOneProcess(oneExecution[proc],metric,proc,unit)   \n",
    "        if unit != '%':\n",
    "            plotOneProcess(sumExecution[proc],'sum_' + metric,proc,unit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs( plotOutputPath + 'overleaf', exist_ok=True)\n",
    "\n",
    "allData = extractData(data,'realtime')\n",
    "oneExecution = rearangeDict(allData,['mean','min','max','median']) \n",
    "plotOneProcess(oneExecution['preprocessing:preprocess'],'realtime','preprocessing:preprocess','min', plotOutputPath + 'overleaf' + os.path.sep, figsize = figsizeS, nCol = 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for v in valuesToExtract:\n",
    "    plot(data,v[0],v[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(plotOutputPath + 'stages', exist_ok=True)\n",
    "\n",
    "def plotSingleMetrics(data,metric,unit,plot=True,optimumLine = False, efficiency = False, hps = False, ylim = None, outPath = plotOutputPath + 'stages'  + os.path.sep, figsize = figsizeO, title = \"duration\"):\n",
    "    plt.rcParams[\"figure.figsize\"] = figsize\n",
    "    allData = {}\n",
    "    for nodes in data:\n",
    "        results = []\n",
    "        for run in data[nodes]:\n",
    "            if metric in data[nodes][run]:\n",
    "                results.append(data[nodes][run][metric])\n",
    "        if len(results) > 0:\n",
    "            allData[nodes] = np.median(results)\n",
    "    print(metric,allData)\n",
    "    \n",
    "    originalValue = None\n",
    "    if 'original' in allData:\n",
    "        originalValue = allData['original']\n",
    "        del allData['original']\n",
    "        \n",
    "    nfValue = None\n",
    "    if 'nf' in allData:\n",
    "        nfValue = allData['nf']\n",
    "        del allData['nf']\n",
    "    \n",
    "    lists = sorted(allData.items()) # sorted by key, return a list of tuples\n",
    "    x, y = zip(*lists)\n",
    "    y0 = y[0] \n",
    "    if efficiency :\n",
    "        y = (y0 / np.array(x)) / np.array(y)\n",
    "    else:\n",
    "        y = y / y0\n",
    "    \n",
    "    if '-' in metric:\n",
    "        markerTuple = markerMultiple[metric[:metric.index('-')]]\n",
    "    else:\n",
    "        markerTuple = ('black','solid','x','v')\n",
    "    \n",
    "    #plt.plot(list(map(int,x)), list(map(float,y)), label = metric,linewidth=linethicknes, marker=markerTuple[2],linestyle=markerTuple[1],color=markerTuple[0])\n",
    "    plt.plot(list(map(int,x)), list(map(float,y)), label = metric,linewidth=linethicknes,linestyle=markerTuple[1],color=markerTuple[0])\n",
    "    plt.title(metric)\n",
    "    plt.xlabel('# of nodes')\n",
    "    \n",
    "    plt.ylabel( title )\n",
    "    \n",
    "    xLabels = np.array(x)\n",
    "    \n",
    "    if originalValue is not None:\n",
    "        print('original')\n",
    "        xVal = (y0 / comparableNodes) / originalValue if efficiency else originalValue / y0\n",
    "        plt.scatter(comparableNodes, xVal, label = metric + 'Original',linewidth=linethicknes, marker=markerTuple[3],color=markerTuple[0])\n",
    "        \n",
    "    if nfValue is not None:\n",
    "        xVal = (y0 / comparableNodes) / nfValue if efficiency else nfValue / y0\n",
    "        plt.scatter(comparableNodes, xVal, label = metric + 'NF',linewidth=linethicknes, marker=markerTuple[2],color=markerTuple[0])\n",
    "        \n",
    "    if hps or nfValue is not None:\n",
    "        x = list(x)\n",
    "        x.append(14)\n",
    "        x.sort()\n",
    "        xLabels = x.copy()\n",
    "        xLabels[x.index(14)] = 'HPS'\n",
    "        \n",
    "    \n",
    "    if optimumLine:\n",
    "        plt.plot(np.array(list(map(int,x))), 1. / np.array(list(map(int,x))), label = 'Optimal Scaling', color='red',linewidth=0.5, zorder=-100) \n",
    "        \n",
    "    plt.grid(color='grey', linestyle='-', linewidth=.1)\n",
    "    \n",
    "    plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()]) \n",
    "    \n",
    "    \n",
    "    plt.xticks(x,xLabels)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    \n",
    "    if plot:\n",
    "        plt.legend()\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        # sort both labels and handles by labels\n",
    "        labels, handles = labelLegend(labels,handles)\n",
    "        plt.gca().legend(handles, labels)\n",
    "        plt.savefig(outPath + metric + '.png', bbox_inches='tight', dpi = dpi)\n",
    "        plt.title(None)\n",
    "        plt.savefig(outPath + metric + '.pdf', bbox_inches='tight', dpi = dpi)\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "            \n",
    "    plt.rcParams[\"figure.figsize\"] = figsizeO\n",
    "            \n",
    "def plotMultipleMetrics(metrics,endsWith,data,imageName,optimumLine = True, efficiency = False, hps = False, ylim = None, outPath = plotOutputPath + 'stages'  + os.path.sep, figsize = figsizeO, nCol = 1, title = \"duration\"):\n",
    "    first = optimumLine\n",
    "    for sm in metrics:\n",
    "        if(sm[0].endswith(endsWith)):\n",
    "            plotSingleMetrics(data,sm[0],sm[1],False,first, efficiency, hps, ylim,figsize=figsize,title=title)\n",
    "            first = False\n",
    "            \n",
    "    plt.legend(loc = 'lower left' if efficiency else 'upper right')\n",
    "    \n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    # sort both labels and handles by labels\n",
    "    labels, handles = labelLegend(labels,handles)\n",
    "    plt.gca().legend(handles, labels, ncol = nCol)\n",
    "    \n",
    "    plt.title(imageName)\n",
    "    plt.savefig(outPath + imageName + '.png', bbox_inches='tight', dpi = dpi)\n",
    "    plt.title(None)\n",
    "    plt.savefig(outPath + imageName + '.pdf', bbox_inches='tight', dpi = dpi)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    \n",
    "\n",
    "singleMetrics = [\n",
    "    ('totalRuntime','min',True, 'total runtime in comparison to one node'),\n",
    "    ('sumRuntime','h',False, 'cum. runtime in comparison to one node'),\n",
    "    ('cpuRuntime','h',False, 'cum. CPU hours in comparison to one node'),\n",
    "    ('requestedCPURuntime','h',False, 'requested CPU hours in comparison to one node'),\n",
    "    ('stagePreprocessMerge-Duration','min'),\n",
    "    ('stageHigherLevel-Duration','min'),\n",
    "    ('stageHigherLevel-RealtimeSum','h'),\n",
    "    ('stageHigherLevel-CpuRuntime','h'),\n",
    "    ('stagePreprocess-Duration','min'),\n",
    "    ('stagePreprocess-RealtimeSum','h'),\n",
    "    ('stagePreprocess-CpuRuntime','h'),\n",
    "    ('stageMerge-Duration','min'),\n",
    "    ('stageMerge-RealtimeSum','h'),\n",
    "    ('stageMerge-CpuRuntime','h')\n",
    "]  \n",
    "\n",
    "markerMultiple = {\n",
    "    'stageMerge' : ('r',':','1'),'stageHigherLevel' : ('g','solid','2','v'),'stagePreprocess' : ('black','--','3'),'stagePreprocessMerge': ('b','-.','4','^')\n",
    "}\n",
    "\n",
    "for sm in singleMetrics[:4]:\n",
    "    plotSingleMetrics(data,sm[0],sm[1], optimumLine=sm[2], title = sm[3] )\n",
    "\n",
    "plotMultipleMetrics(singleMetrics[4:],'Sum',data,'stagesSumRuntime', False, title = \"cum. runtime in comparison to one node\")\n",
    "plotMultipleMetrics(singleMetrics[4:],'Duration',data,'stagesDurationEfficiency', False, True, True,(0,1.01), nCol = 2, title = \"efficiency in comparison to one node\")\n",
    "plotMultipleMetrics(singleMetrics[4:],'Duration',data,'stagesDuration', True, False, True, title = \"duration in comparison to one node\")\n",
    "plotMultipleMetrics(singleMetrics[4:],'CpuRuntime',data,'stagesCpuRuntime', False, title = \"cum. CPU hours in comparison to one node\")\n",
    "\n",
    "\n",
    "plotSingleMetrics(data,singleMetrics[0][0],singleMetrics[0][1], optimumLine=singleMetrics[0][2], outPath=plotOutputPath + 'overleaf'  + os.path.sep, figsize=figsizeS, title = singleMetrics[0][3])\n",
    "\n",
    "plotMultipleMetrics(singleMetrics[4:],'Sum',data,'stagesSumRuntime', False, outPath=plotOutputPath + 'overleaf'  + os.path.sep, figsize=figsizeS, title = \"cum. runtime in comparison to one node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "os.makedirs(plotOutputPath + 'overleaf', exist_ok=True)\n",
    "files = ['higherLevel-processHigherLevel-percent_cpu']\n",
    "filesStages = ['stagesDuration','stagesDurationEfficiency']\n",
    "for f in files:\n",
    "    shutil.copy(plotOutputPath + f + '.pdf', plotOutputPath + 'overleaf')\n",
    "for f in filesStages:\n",
    "    shutil.copy(plotOutputPath + 'stages' + os.path.sep + f + '.pdf', plotOutputPath + 'overleaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important metrics:\n",
    "def getRuntime(node,metric):\n",
    "    #if str(node) == '14':\n",
    "    #    a = getRuntime(10,metric)\n",
    "    #    b = getRuntime(15,metric)\n",
    "    #    return np.interp(14, [10,15], [a,b])\n",
    "        \n",
    "    results = []\n",
    "    for run in data[node]:\n",
    "        results.append(data[node][run][metric])\n",
    "    return np.median(results)\n",
    "\n",
    "def isNumber(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def findNodesForY(y, metric):\n",
    "    nodes = []\n",
    "    for n in data:\n",
    "        if isNumber(n):\n",
    "            nodes.append(int(n))\n",
    "    nodes.sort()\n",
    "    values = []\n",
    "    for n in nodes:\n",
    "        values.append(getRuntime(n,metric))\n",
    "    index = 0\n",
    "    for k in range(1, len(values)):\n",
    "        if( values[ k - 1 ] >= y and values[ k ] <= y ):\n",
    "            index = k\n",
    "            break\n",
    "    if(index == 0):\n",
    "        raise Exception('No value found')\n",
    "    m = ((values[k]-values[k-1])/(nodes[k]-nodes[k-1]))\n",
    "    r = nodes[k-1] + (y - values[k-1]) / m\n",
    "    return r\n",
    "\n",
    "print()\n",
    "print('Total Runtime')\n",
    "\n",
    "wfDuration1Node = getRuntime(1,'totalRuntime')\n",
    "wfDuration21Node = getRuntime(21,'totalRuntime')\n",
    "wfDuration14Node = getRuntime(14,'totalRuntime')\n",
    "wfDurationNFNode = getRuntime('nf','totalRuntime')\n",
    "wfDurationOriginalNode = getRuntime('original','totalRuntime')\n",
    "\n",
    "print('Runtime in min 1:',wfDuration1Node,'21:',wfDuration21Node,'14:',wfDuration14Node,'NF',wfDurationNFNode, 'Orig', wfDurationOriginalNode)\n",
    "print('Runtime 1 -> 21',wfDuration1Node / wfDuration21Node,'x')\n",
    "print('Runtime NF vs 14',1 - wfDurationNFNode / wfDuration14Node,'%')\n",
    "print('Runtime Original higher 21',wfDurationOriginalNode / wfDuration21Node - 1,'%')\n",
    "print('Runtime NF vs Original',wfDurationNFNode / wfDurationOriginalNode - 1,'%')\n",
    "\n",
    "print()\n",
    "print('Preprocessing')\n",
    "print()\n",
    "\n",
    "preprocessDuration1Node = getRuntime(1,'stagePreprocess-Duration')\n",
    "print('stagePreprocess-Duration 1 node', preprocessDuration1Node, 'm')\n",
    "preprocessDuration21Node = getRuntime(21,'stagePreprocess-Duration')\n",
    "print('stagePreprocess-Duration 21 node', preprocessDuration21Node, 'm')\n",
    "preprocessDuration14Node = getRuntime(14,'stagePreprocess-Duration')\n",
    "print('stagePreprocess-Duration 14 node', preprocessDuration14Node, 'm')\n",
    "preprocessDurationNFNode = getRuntime('nf','stagePreprocess-Duration')\n",
    "print('stagePreprocess-Duration NF node', preprocessDurationNFNode, 'm')\n",
    "print('stagePreprocess-Duration 1 -> 21 nodes improvement', preprocessDuration1Node / preprocessDuration21Node, 'x')\n",
    "print('stagePreprocess-Duration 21 efficiency', (preprocessDuration1Node / 21) / preprocessDuration21Node, '%')\n",
    "\n",
    "stagePreprocessRealtimeSum14Node = getRuntime(14,'stagePreprocess-RealtimeSum')\n",
    "stagePreprocessRealtimeSumNFNode = getRuntime('nf','stagePreprocess-RealtimeSum')\n",
    "\n",
    "print('stagePreprocess-RealtimeSum NF overhead', (stagePreprocessRealtimeSumNFNode / stagePreprocessRealtimeSum14Node) - 1, '%')\n",
    "\n",
    "print()\n",
    "print('Merge')\n",
    "print()\n",
    "\n",
    "mergeDuration1Node = getRuntime(1,'stageMerge-Duration')\n",
    "mergeDuration21Node = getRuntime(21,'stageMerge-Duration')\n",
    "mergeDuration21NodeEfficiency = ((mergeDuration1Node / 21) / mergeDuration21Node)\n",
    "print('stageMerge-Duration 21 efficiency', mergeDuration21NodeEfficiency / 21 * 100, '%')\n",
    "\n",
    "print()\n",
    "print('Preproces - Merge')\n",
    "print()\n",
    "\n",
    "preprocessmergeDuration1Node = getRuntime(1,'stagePreprocessMerge-Duration')\n",
    "preprocessmergeDuration14Node = getRuntime(14,'stagePreprocessMerge-Duration')\n",
    "preprocessmergeDuration21Node = getRuntime(21,'stagePreprocessMerge-Duration')\n",
    "preprocessmergeDurationOriginalNode = getRuntime('original','stagePreprocessMerge-Duration')\n",
    "preprocessMergeDuration14NodeEfficiency = ((preprocessmergeDuration1Node / 14) / preprocessmergeDuration14Node)\n",
    "preprocessMergeDurationOriginalNodeEfficiency = ((preprocessmergeDuration1Node / 14) / preprocessmergeDurationOriginalNode)\n",
    "print('stagePreprocessMerge-Duration 14 efficiency', preprocessMergeDuration14NodeEfficiency * 100, '%')\n",
    "print('stagePreprocessMerge-Duration Original efficiency', preprocessMergeDurationOriginalNodeEfficiency * 100, '%')\n",
    "print('stagePreprocessMerge-Duration outperform original', findNodesForY(preprocessmergeDurationOriginalNode,'stagePreprocessMerge-Duration'), 'nodes')\n",
    "print('stagePreprocessMerge-Duration 21 earlier than Original', (1 - preprocessmergeDuration21Node / preprocessmergeDurationOriginalNode) * 100, '%')\n",
    "\n",
    "print()\n",
    "print('Higher Level')\n",
    "print()\n",
    "\n",
    "higherLevelDuration1Node = getRuntime(1,'stageHigherLevel-Duration')\n",
    "print('higherLevelDuration1Node-Duration 1 node', higherLevelDuration1Node, 'min')\n",
    "\n",
    "higherLevelDuration14Node = getRuntime(14,'stageHigherLevel-Duration')\n",
    "higherLevelDuration21Node = getRuntime(21,'stageHigherLevel-Duration')\n",
    "higherLevelDurationNFNode = getRuntime('nf','stageHigherLevel-Duration')\n",
    "higherLevelDurationOriginalNode = getRuntime('original','stageHigherLevel-Duration')\n",
    "\n",
    "print('stageHigherLevel runtime with 1 nodes higher 21 node', higherLevelDuration1Node / higherLevelDuration21Node, 'x')\n",
    "higherLevelDuration21NodeEfficiency = ((higherLevelDuration1Node / 21) / higherLevelDuration21Node)\n",
    "print('stagePreprocessMerge-Duration 21 efficiency', higherLevelDuration21NodeEfficiency * 100, '%')\n",
    "\n",
    "\n",
    "\n",
    "higherLevelRChar1Node = getRuntime(1,'stageHigherLevel-rchar') / 1024\n",
    "higherLevelWChar1Node = getRuntime(1,'stageHigherLevel-wchar') / 1024\n",
    "print('Higher Level I/O: r:',higherLevelRChar1Node,'gb','w:', higherLevelWChar1Node,'gb')\n",
    "\n",
    "\n",
    "higherLevelRealtimeSum1Node = getRuntime(1,'stageHigherLevel-RealtimeSum')\n",
    "higherLevelRealtimeSum20Node = getRuntime(20,'stageHigherLevel-RealtimeSum')\n",
    "\n",
    "print('stagePreprocessMerge-RuntimeSum Increase 1->20', higherLevelRealtimeSum20Node / higherLevelRealtimeSum1Node * 100, '%')\n",
    "\n",
    "higherLevelDuration14NodeEfficiency = ((higherLevelDuration1Node / 14) / higherLevelDuration14Node)\n",
    "higherLevelDurationOriginalNodeEfficiency = ((higherLevelDuration1Node / 14) / higherLevelDurationOriginalNode)\n",
    "higherLevelDurationNFNodeEfficiency = ((higherLevelDuration1Node / 14) / higherLevelDurationNFNode)\n",
    "print('higherLevelMerge-Duration 14 efficiency', higherLevelDuration14NodeEfficiency * 100, '%')\n",
    "print('higherLevelMerge-Duration Original efficiency', higherLevelDurationOriginalNodeEfficiency * 100, '%')\n",
    "print('higherLevelMerge-Duration NF efficiency', higherLevelDurationNFNodeEfficiency * 100, '%')\n",
    "print('stageHigherLevel runtime with 21 nodes vs Original node', higherLevelDuration21Node / higherLevelDurationOriginalNode, '%')\n",
    "\n",
    "print()\n",
    "print('Discussion')\n",
    "print()\n",
    "\n",
    "\n",
    "totalDuration21NodeEfficiency = ((wfDuration1Node / 21) / wfDuration21Node)\n",
    "print('21 Node total efficiency', totalDuration21NodeEfficiency * 100, '%')\n",
    "print('21 Node preprocessing share', preprocessDuration21Node / wfDuration21Node * 100, '%')\n",
    "higherLevelDuration21NodeEfficiency = ((higherLevelDuration1Node / 21) / higherLevelDuration21Node)\n",
    "print('higherLevelMerge-Duration 21 efficiency', higherLevelDuration21NodeEfficiency * 100, '%')\n",
    "\n",
    "\n",
    "print()\n",
    "print('Conclusion')\n",
    "print()\n",
    "\n",
    "print('total runtime outperform original', findNodesForY(preprocessmergeDurationOriginalNode,'totalRuntime'), 'nodes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
